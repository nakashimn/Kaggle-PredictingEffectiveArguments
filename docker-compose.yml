version: '3.3'
services:
  predicting-effective-arguments:
    build: ./Dockerfile
    container_name: predicting-effective-arguments
    hostname: predicting-effective-arguments
    shm_size: '28gb'
    deploy:
      resources:
        reservations:
          devices:
           - driver: nvidia
             capabilities: ["gpu"]
    volumes:
      - ./:/workspace:cached
      - ./kaggle:/kaggle:cached
      - ${DATASTORAGE_PATH}:/data_storage:cached
    environment:
      TZ: Asia/Tokyo
      KAGGLE_USERNAME: ${KAGGLE_USERNAME}
      KAGGLE_KEY: ${KAGGLE_KEY}
      MLFLOW_TRACKING_URI: /workspace/log/mlruns/
      TRAINING: "true"
      DISPLAY: host.docker.internal:0.0
      PULSE_SERVER: tcp:host.docker.internal
    tty: true
